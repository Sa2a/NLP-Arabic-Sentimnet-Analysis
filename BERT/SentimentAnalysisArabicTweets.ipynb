{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj5zGpnNJDAH"
      },
      "source": [
        "# Model and Tokenizer initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk0ku-y8JCYh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !pip install transformers\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "\n",
        "#============= Initialize Arabic Bert =============#\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"asafaya/bert-base-arabic\", num_labels=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYs4XrvS4WL2"
      },
      "source": [
        "# Initial Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PB3PRUpITy0",
        "outputId": "f7fa838e-fe88-43c7-ab07-31d195efe4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qalsadi\n",
            "  Downloading qalsadi-0.4.5-py3-none-any.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting naftawayh>=0.3\n",
            "  Downloading Naftawayh-0.4-py3-none-any.whl (332 kB)\n",
            "\u001b[K     |████████████████████████████████| 332 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting libqutrub>=1.2.3\n",
            "  Downloading libqutrub-1.2.4.1-py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 72.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from qalsadi) (0.16.0)\n",
            "Collecting pickledb>=0.9.2\n",
            "  Downloading pickleDB-0.9.2.tar.gz (3.7 kB)\n",
            "Collecting pyarabic>=0.6.7\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 70.4 MB/s \n",
            "\u001b[?25hCollecting tashaphyne>=0.3.4.1\n",
            "  Downloading Tashaphyne-0.3.6-py3-none-any.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 52.7 MB/s \n",
            "\u001b[?25hCollecting arramooz-pysqlite>=0.3\n",
            "  Downloading arramooz_pysqlite-0.3-py3-none-any.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 24.2 MB/s \n",
            "\u001b[?25hCollecting Arabic-Stopwords>=0.3\n",
            "  Downloading Arabic_Stopwords-0.3-py3-none-any.whl (353 kB)\n",
            "\u001b[K     |████████████████████████████████| 353 kB 67.0 MB/s \n",
            "\u001b[?25hCollecting alyahmor>=0.1\n",
            "  Downloading alyahmor-0.1.5-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 600 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from qalsadi) (1.15.0)\n",
            "Building wheels for collected packages: pickledb\n",
            "  Building wheel for pickledb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickledb: filename=pickleDB-0.9.2-py3-none-any.whl size=4271 sha256=45c1a605976ccd5182becaf8968464d60313a015ed22567817c3176e24f0262d\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/34/42/9a7f94099208ce3d32638d98586a5a50f821db2fc75a3bdaae\n",
            "Successfully built pickledb\n",
            "Installing collected packages: pyarabic, tashaphyne, libqutrub, arramooz-pysqlite, pickledb, naftawayh, Arabic-Stopwords, alyahmor, qalsadi\n",
            "Successfully installed Arabic-Stopwords-0.3 alyahmor-0.1.5 arramooz-pysqlite-0.3 libqutrub-1.2.4.1 naftawayh-0.4 pickledb-0.9.2 pyarabic-0.6.15 qalsadi-0.4.5 tashaphyne-0.3.6\n"
          ]
        }
      ],
      "source": [
        "pip install qalsadi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEAYbjZnR2je",
        "outputId": "199cd82a-d66c-4bd9-e98b-6d7675c546b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored 'tokenizer' (BertTokenizerFast)\n",
            "Stored 'model' (BertForSequenceClassification)\n"
          ]
        }
      ],
      "source": [
        "%store tokenizer\n",
        "%store model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOFtulztZb9U",
        "outputId": "2e09b467-71ba-4904-cc1b-0b4cb1d1373f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no stored variable tokenizer\n",
            "no stored variable model\n"
          ]
        }
      ],
      "source": [
        "%store -r tokenizer\n",
        "%store -r model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1t3hUZCRdVY",
        "outputId": "b3daeae2-8696-4988-d0bc-16c04d86e429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gH97C8ALPLV",
        "outputId": "422c3874-fff9-4aff-8a5d-303f77c2c07b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "# stopwords.words('arabic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "fgwOaTnBoQ-q",
        "outputId": "9944722b-5f06-4d19-97f8-5374fa3cf6fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>' و انتهى مشوار الخواجة '</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>' مش عارف ابتدى مذاكره منين :/ '</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>' إذ خانت المرأة فهي تبحث عن الإهتمام .. و إذ ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>' يا حبيبتي البعد ناار قلبي داب من الانتظار ♡ '</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>' \"\"\"يا سامحك الله، من علّمك أن تكون خيبة؟\"\"\"\" '</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>' خى مالها قفلت من كل حتة كده لييه ! '</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>' الناس اللى حضرت حفلات البرلمان القديم ياريت ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet class\n",
              "0  ' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...   pos\n",
              "1  ' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...   pos\n",
              "2                          ' و انتهى مشوار الخواجة '   neg\n",
              "3                   ' مش عارف ابتدى مذاكره منين :/ '   neg\n",
              "4  ' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...   neg\n",
              "5  ' إذ خانت المرأة فهي تبحث عن الإهتمام .. و إذ ...   neg\n",
              "6    ' يا حبيبتي البعد ناار قلبي داب من الانتظار ♡ '   pos\n",
              "7   ' \"\"\"يا سامحك الله، من علّمك أن تكون خيبة؟\"\"\"\" '   neg\n",
              "8             ' خى مالها قفلت من كل حتة كده لييه ! '   neg\n",
              "9  ' الناس اللى حضرت حفلات البرلمان القديم ياريت ...   neg"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import qalsadi.lemmatizer\n",
        "# lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
        "#============= Read CSV and apply data preperation =============#\n",
        "directory = \"D:/DEBI/Uottawa/Data Science Applications/kaggle/\"\n",
        "\n",
        "data_frame = pd.read_csv(directory+\"/train.csv\")\n",
        "data_frame.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkND0STBy0rz",
        "outputId": "30f3c995-6038-4e2b-f28a-ac506eafe192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2059, 2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ_jnkbPK15D"
      },
      "outputs": [],
      "source": [
        "def lem_stopwords_tokenize2(text):\n",
        "  lemmas = lemmer.lemmatize_text(text , return_pos=True)\n",
        "  stop_words = set(stopwords.words('arabic'))\n",
        "  clean_words=\"\"\n",
        "  for word_tupel in lemmas:\n",
        "    # print(word_tupel[1])\n",
        "    if word_tupel[1] != \"stopword\" or (word_tupel[0] not in stop_words):\n",
        "      clean_words+=word_tupel[0]+\" \"\n",
        "  # clean_words.append('[SEP]') \n",
        "  return clean_words[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ghYzTIQWPSz"
      },
      "outputs": [],
      "source": [
        "def lem_stopwords_tokenize(text):\n",
        "  lemmas = lemmer.lemmatize_text(text , return_pos=True)\n",
        "  # stop_words = set(stopwords.words('arabic'))\n",
        "  clean_words=\"\"\n",
        "  for word_tupel in lemmas:\n",
        "    # print(word_tupel[1])\n",
        "    # if word_tupel[1] != \"stopword\" or (word_tupel[0] not in stop_words):\n",
        "    clean_words+=word_tupel[0]+\" \"\n",
        "  # clean_words.append('[SEP]') \n",
        "  return clean_words[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcbAGx8sMzW6",
        "outputId": "639ff049-f572-48d0-dbee-4e610e69330b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "جاامد اللهم اللللله حلل علمتني_الحياه أن الذين أعاش على أرض ليسوا ملائك بل بشر قد أصاب قد أخطأ لا جاز أن حكم على شخص من موقف واحد تعامل مع في\n"
          ]
        }
      ],
      "source": [
        "text = 'جاامد اللهم اللللله  حللو علمتني_الحياه أن الذين يعيشون على الأرض ليسوا ملائكة بل بشر قد يصيبوا وقد يخطئوا فلا يجوز أن أحكم على شخص من موقف واحد تعاملت معه فيه'\n",
        "x= lem_stopwords_tokenize(text)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHhRdowJaiE6",
        "outputId": "dc59846d-5863-4903-ac0f-b0216e448609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'علمت', '##ني', '_', 'الحياه', 'ان', 'الذين', 'يعيشون', 'على', 'الارض', 'ليسوا', '[SEP]']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'علمت',\n",
              " '_',\n",
              " 'الحياه',\n",
              " 'ان',\n",
              " 'الذين',\n",
              " 'يعيشون',\n",
              " 'على',\n",
              " 'الارض',\n",
              " 'ليسوا',\n",
              " '[SEP]']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# payload['text'] = \"علمتني_الحياه أن الذين يعيشون على الأرض ليسوا\"\n",
        "# data = requests.post(url, data=payload)\n",
        "# print(data.text)\n",
        "# result = json.loads(data.text)\n",
        "# print(result) \n",
        "tokens = tokenizer(\"علمتني_الحياه أن الذين يعيشون على الأرض ليسوا\").tokens()\n",
        "print(tokens)\n",
        "t = list(filter(lambda x: \"#\" not in x,tokens))\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ADzCXR_03zNY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\river\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        }
      ],
      "source": [
        "# import dataclasses\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import re\n",
        "\n",
        "# #============= Read CSV and apply data preperation =============#\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/train.csv\")\n",
        "\n",
        "# # clean-up: remove #tags, http links and special symbols\n",
        "# \n",
        "# df.iloc[:,0] = df.iloc[:,0].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "# df.iloc[:,0] = df.iloc[:,0].apply(lambda x: re.sub(r'[@|#]\\S*', '', x))\n",
        "# df.iloc[:,0] = df.iloc[:,0].apply(lambda x: re.sub(r'\"+', '', x))\n",
        "\n",
        "# # Remove arabic signs\n",
        "# df.iloc[:,0] = df.iloc[:,0].apply(lambda x: re.sub(r'([@A-Za-z0-9_ـــــــــــــ]+)|[^\\w\\s]|#|http\\S+', '', x))\n",
        "\n",
        "# # Remove repeated letters like \"الللللللللللللللله\" to \"الله\"\n",
        "# df.iloc[:,0] = df.iloc[:,0].apply(lambda x: x[0:2] + ''.join([x[i] for i in range(2, len(x)) if x[i]!=x[i-1] or x[i]!=x[i-2]]))\n",
        "\n",
        "# # Tokenize the sentences using bert tokenizer\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(directory+\"araBERT/araBERT_tokenizer\")\n",
        "general_filter = lambda x: re.sub(r'([@A-Za-z0-9ـــــــــــــ]+)|[^\\w\\s]|#|http\\S+|[\\s]{2,}', '', x)\n",
        "rem_repeated_letters = lambda x: x[0:2] + ''.join([x[i] for i in range(2, len(x)) if x[i]!=x[i-1] or x[i]!=x[i-2]])\n",
        "heart_emotion_translate = lambda x: re.sub(r'[♥|❤️|❤|♡]+', 'قلب', x)\n",
        "happy_emotion_translate = lambda x: re.sub(r'(\\^[._]?\\^)+', 'سعيد', x)\n",
        "sad_emotion_translate = lambda x: re.sub(r'(-[._]?-)+', 'حزين', x)\n",
        "\n",
        "def pre_process(data_frame):\n",
        "  data_frame_x = data_frame.copy()\n",
        "  # data_frame_x.tweet = data_frame_x.tweet.apply(lambda x: x[2:-2]).apply(heart_emotion_translate).apply(happy_emotion_translate).apply(sad_emotion_translate).apply(general_filter).apply(rem_repeated_letters).apply(lem_stopwords_tokenize)\n",
        "\n",
        "  data_frame_x[\"bert_tokens\"] = data_frame_x.tweet.apply(lambda x:tokenizer(x).tokens())# list(filter(lambda x: \"#\" not in x, tokenizer(x).tokens())))\n",
        "  return data_frame_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hH0v5PJ8R8L7",
        "outputId": "7af27940-a5c6-4ac8-c117-a84ff735c34a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'علمتني_الحياه أعاش أرض ملاء بشر صابي خطأ جاز'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "st = lem_stopwords_tokenize(\"علمتني_الحياه أعاش أرض ملائك بشر أصاب أخطأ جاز\")\n",
        "st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6ZE6_LUaGDNq",
        "outputId": "cc8e07de-e057-44af-a245-2846a306788a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "      <th>bert_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...</td>\n",
              "      <td>pos</td>\n",
              "      <td>[[CLS], ', #, علمتني, _, الح, ##يا, ##ه, أن, ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...</td>\n",
              "      <td>pos</td>\n",
              "      <td>[[CLS], ', #, ميري, _, كرس, ##مس, كل, سن, ##ة,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>' و انتهى مشوار الخواجة '</td>\n",
              "      <td>neg</td>\n",
              "      <td>[[CLS], ', و, انتهى, مشوار, الخ, ##واج, ##ة, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>' مش عارف ابتدى مذاكره منين :/ '</td>\n",
              "      <td>neg</td>\n",
              "      <td>[[CLS], ', مش, عارف, ابتد, ##ى, مذاكر, ##ه, من...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...</td>\n",
              "      <td>neg</td>\n",
              "      <td>[[CLS], ', @, m, ##sk, ##ha, ##fa, ##g, ##i, إ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet class  \\\n",
              "0  ' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...   pos   \n",
              "1  ' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...   pos   \n",
              "2                          ' و انتهى مشوار الخواجة '   neg   \n",
              "3                   ' مش عارف ابتدى مذاكره منين :/ '   neg   \n",
              "4  ' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...   neg   \n",
              "\n",
              "                                         bert_tokens  \n",
              "0  [[CLS], ', #, علمتني, _, الح, ##يا, ##ه, أن, ا...  \n",
              "1  [[CLS], ', #, ميري, _, كرس, ##مس, كل, سن, ##ة,...  \n",
              "2  [[CLS], ', و, انتهى, مشوار, الخ, ##واج, ##ة, '...  \n",
              "3  [[CLS], ', مش, عارف, ابتد, ##ى, مذاكر, ##ه, من...  \n",
              "4  [[CLS], ', @, m, ##sk, ##ha, ##fa, ##g, ##i, إ...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pre_process(data_frame)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCEQ5c7JIZT3"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/train.csv\")\n",
        "df.iloc[\"fasttext\"] = dataset.iloc[:, 1].apply(lambda x: '__label__' + x)\n",
        "ds.iloc[:, 1] = ds.iloc[:, 1].apply(lambda x: '__label__' + x)\n",
        "# Skipgram model :\n",
        "model = fasttext.train_unsupervised(df.tweet, model='skipgram')\n",
        "\n",
        "# or, cbow model :\n",
        "model = fasttext.train_unsupervised(df.tweet, model='cbow')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ilItbiZ61hGT"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "bert_tokens = df[\"bert_tokens\"]\n",
        "labels = df[\"class\"]\n",
        "\n",
        "# Apply label encoding over the labels\n",
        "le = preprocessing.LabelEncoder()\n",
        "Encodedlabels =le.fit_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFwzO7StaXT0",
        "outputId": "018df562-f8e5-4381-d087-7ddcce686a22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 0, ..., 2, 0, 1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Encodedlabels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO6bLSh2I5GL"
      },
      "source": [
        "# Padding and attention mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "onXUUeTK1Q4i"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32md:\\DEBI\\Uottawa\\Data Science Applications\\kaggle\\BERT\\Copy_of_SentimentAnalysisArabicTweets.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DEBI/Uottawa/Data%20Science%20Applications/kaggle/BERT/Copy_of_SentimentAnalysisArabicTweets.ipynb#ch0000021?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DEBI/Uottawa/Data%20Science%20Applications/kaggle/BERT/Copy_of_SentimentAnalysisArabicTweets.ipynb#ch0000021?line=2'>3</a>\u001b[0m \u001b[39m# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DEBI/Uottawa/Data%20Science%20Applications/kaggle/BERT/Copy_of_SentimentAnalysisArabicTweets.ipynb#ch0000021?line=3'>4</a>\u001b[0m \u001b[39m# In the original paper, the authors used a length of 512.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DEBI/Uottawa/Data%20Science%20Applications/kaggle/BERT/Copy_of_SentimentAnalysisArabicTweets.ipynb#ch0000021?line=4'>5</a>\u001b[0m MAX_LEN \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 128\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in bert_tokens]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-tjO1PLbPQh",
        "outputId": "67f6593b-0af8-42c3-bc7a-46a0c986ec65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[    2 11574  1857    41 22915  1732  2481  1903  2075  1747  3648 17676\n",
            "  6864  2164  2000  4821  2048  7824  2048 20818  1783  7605  1732  3925\n",
            "  1747  2594  1726  5199  2807 11837  1776  1725     3     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "print(input_ids[0])\n",
        "print(attention_masks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q72BkkMNI3aW"
      },
      "source": [
        "# To tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxIrSSWV2DDP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, Encodedlabels, \n",
        "                                                            random_state=2018, test_size=0.08)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.08)\n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXT5AmKLbyZR",
        "outputId": "6aa66faf-2350-4d07-ccfb-a8678081b3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[    2, 24192, 27275,  ...,     0,     0,     0],\n",
            "        [    2,  7153,  6058,  ...,     0,     0,     0],\n",
            "        [    2,    41,  1882,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2,  3947,  7881,  ...,     0,     0,     0],\n",
            "        [    2,  1882,  2091,  ...,     0,     0,     0],\n",
            "        [    2,  2300, 14684,  ...,     0,     0,     0]]), tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.]]), tensor([0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 0, 0, 0, 2, 2, 0])]\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "  print(batch)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao7E_9NgI0yg"
      },
      "source": [
        "# Set optimizer parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBOHOHQn3CJj"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay_rate': 0.01},\n",
        "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay_rate': 0.0}]\n",
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "#optimizer = BertAdam(optimizer_grouped_parameters,lr=2e-5,warmup=.1)\n",
        "optimizer = optim.AdamW(optimizer_grouped_parameters,lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmyUEzpf7e-C"
      },
      "outputs": [],
      "source": [
        "# loss = model(train_data[:1][0], attention_mask=train_data[:1][1], labels=train_data[:1][2])\n",
        "# loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "# loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg_r0FF_IzfA"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDUxsUyL3Lmy",
        "outputId": "83548781-8bda-434a-a8cc-892773532943"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.9255277509448909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [00:38<05:45, 38.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5886363636363636\n",
            "Train loss: 0.6446525204081496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [01:18<05:13, 39.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5897727272727272\n",
            "Train loss: 0.3770290895545182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [01:58<04:36, 39.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6\n",
            "Train loss: 0.17622454678874558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [02:37<03:57, 39.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6113636363636363\n",
            "Train loss: 0.08925188246707455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [03:17<03:18, 39.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6522727272727272\n",
            "Train loss: 0.059494208344923596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [03:57<02:38, 39.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5590909090909091\n",
            "Train loss: 0.04492107264016669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [04:37<01:59, 39.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5420454545454546\n",
            "Train loss: 0.044588652424741256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [05:16<01:19, 39.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5659090909090909\n",
            "Train loss: 0.03833077619724883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [05:56<00:39, 39.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5704545454545454\n",
            "Train loss: 0.0434560219810086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [06:36<00:00, 39.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5954545454545455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm, trange\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "t = []\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs \n",
        "epochs = 10\n",
        "\n",
        "# Transfer the model to GPU\n",
        "model.to(device)\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids.to(device), token_type_ids=None, attention_mask=b_input_mask.to(device), labels=b_labels.to(device))[\"loss\"]\n",
        "    train_loss_set.append(loss.item())\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    # batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids.to(device), token_type_ids=None, attention_mask=b_input_mask.to(device))\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits[\"logits\"].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACCjdMIxPdoc"
      },
      "source": [
        "# Apply predicition over the submission dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHlHPF8wPhx8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#============= Read CSV and apply data preperation =============#\n",
        "df_submit = pd.read_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/test.csv\")\n",
        "\n",
        "# clean-up: remove #tags, http links and special symbols\n",
        "df_submit.tweet = df_submit.tweet.apply(lambda x: x[2:-2])\n",
        "df_submit.tweet = df_submit.tweet.apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "df_submit.tweet = df_submit.tweet.apply(lambda x: re.sub(r'[@|#]\\S*', '', x))\n",
        "df_submit.tweet = df_submit.tweet.apply(lambda x: re.sub(r'\"+', '', x))\n",
        "\n",
        "# Remove arabic signs\n",
        "df_submit.tweet = df_submit.tweet.apply(lambda x: re.sub(r'([@A-Za-z0-9_ـــــــــــــ]+)|[^\\w\\s]|#|http\\S+', '', x))\n",
        "\n",
        "# Remove repeated letters like \"الللللللللللللللله\" to \"الله\"\n",
        "df_submit.tweet = df_submit.tweet.apply(lambda x: x[0:2] + ''.join([x[i] for i in range(2, len(x)) if x[i]!=x[i-1] or x[i]!=x[i-2]]))\n",
        "\n",
        "# Tokenize the sentences using bert tokenizer\n",
        "df_submit[\"bert_tokens\"] = df_submit.tweet.apply(lambda x: tokenizer(x).tokens())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3oZNpodblu7"
      },
      "outputs": [],
      "source": [
        "df_submit = pd.read_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/test.csv\")\n",
        "\n",
        "df_submit.tweet = df_submit.tweet.apply(lambda x: x[2:-2]).apply(heart_emotion_translate).apply(happy_emotion_translate).apply(sad_emotion_translate).apply(general_filter).apply(rem_repeated_letters).apply(lem_stopwords_tokenize)\n",
        "\n",
        "df_submit[\"bert_tokens\"] = df_submit.tweet.apply(lambda x:tokenizer(x).tokens())# list(filter(lambda x: \"#\" not in x, tokenizer(x).tokens())))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiCekroGRFKG"
      },
      "outputs": [],
      "source": [
        "# df_submit[\"bert_tokens\"] = pre_process(df_submit)\n",
        "df_submit.head()\n",
        "bert_tokens_submit = df_submit[\"bert_tokens\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ3vtlYkRTGb"
      },
      "outputs": [],
      "source": [
        "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 128\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids_submit = [tokenizer.convert_tokens_to_ids(x) for x in bert_tokens_submit]\n",
        "# Pad our input tokens\n",
        "input_ids_submit = pad_sequences(input_ids_submit, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks_submit = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids_submit:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks_submit.append(seq_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58982HhxRLUD"
      },
      "outputs": [],
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "inputs_submit = torch.tensor(input_ids_submit)\n",
        "masks_submit = torch.tensor(attention_masks_submit)\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "batch_size = 16\n",
        "submit_data = TensorDataset(inputs_submit, masks_submit)\n",
        "\n",
        "# do not use shuffle, we need the preds to be in same order\n",
        "submit_dataloader = DataLoader(submit_data, batch_size=batch_size)#, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NfUlXyySAh8"
      },
      "outputs": [],
      "source": [
        "# input, masks = next(iter(submit_dataloader))\n",
        "# out = model(input, attention_mask=masks)[\"logits\"]\n",
        "\n",
        "# pred_flat = np.argmax(out.detach().numpy(), axis=1).flatten()\n",
        "# le.inverse_transform(pred_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZm0cffsRrY9"
      },
      "outputs": [],
      "source": [
        "# Put the model in an evaluation state\n",
        "model.eval()\n",
        "\n",
        "# Transfer model to GPU\n",
        "model.to(device)\n",
        "\n",
        "outputs = []\n",
        "for input, masks in submit_dataloader:\n",
        "  torch.cuda.empty_cache() # empty the gpu memory\n",
        "\n",
        "  # Transfer the batch to gpu\n",
        "  input = input.to(device)\n",
        "  masks = masks.to(device)\n",
        "\n",
        "  # Run inference on the batch\n",
        "  output = model(input, attention_mask=masks)[\"logits\"]\n",
        "\n",
        "  # Transfer the output to CPU again and convert to numpy\n",
        "  output = output.cpu().detach().numpy()\n",
        "\n",
        "  # Store the output in a list\n",
        "  outputs.append(output)\n",
        "\n",
        "# Concatenate all the lists within the list into one list\n",
        "outputs = [x for y in outputs for x in y]\n",
        "\n",
        "# Inverse transform the label encoding\n",
        "pred_flat = np.argmax(outputs, axis=1).flatten()\n",
        "output_labels = le.inverse_transform(pred_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oOuGfmaSza0"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\"Id\":np.arange(1, len(output_labels)+1), \"class\":output_labels})\n",
        "# save (submission)\n",
        "submission.to_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/submission3.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIQobE47LJis"
      },
      "source": [
        "# Use last hidden state as input to an ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEShktfqirIa"
      },
      "outputs": [],
      "source": [
        "model.cpu()\n",
        "BERT = []\n",
        "for i in range(len(train_data)):\n",
        "  out = model.forward(train_data[i:i+1][0], attention_mask=train_data[i:i+1][1], output_hidden_states=True)\n",
        "  Sentence_Embedding = out['hidden_states'][-1][0][0].detach().numpy()\n",
        "  BERT.append(Sentence_Embedding)\n",
        "# print(out.keys())\n",
        "# print(out['hidden_states'][-1].shape)\n",
        "\n",
        "# Use the vector representation of [CLS] token as the sentence embedding\n",
        "# Sentence_Embedding = out['hidden_states'][-1][0][0].detach().numpy()\n",
        "# Sentence_Embedding.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0TYnM-puLjk",
        "outputId": "a63aaba9-e31f-4556-91a1-e487aa778b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored 'BERT' (list)\n"
          ]
        }
      ],
      "source": [
        "%store BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5fa6ZaS1uP37",
        "outputId": "d1bf28e6-3721-41f0-bc57-3c148ef9b7b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c234363d-e5ab-433f-b673-8e74a06b43e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BERT</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.12731451, -0.49048722, 0.8446229, 0.259153...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.007940845, -0.35844922, 0.64526886, 1.4159...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.14694825, -0.15108207, 0.61844623, 0.22090...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.39919105, -0.77086115, 0.91552955, 0.41431...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.37260002, -0.15834673, 0.7876212, 1.0688679...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1889</th>\n",
              "      <td>[-0.08940428, -0.048215955, 0.54252553, 0.1527...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1890</th>\n",
              "      <td>[-0.09964228, 0.2793295, -1.509599, -0.6494946...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>[1.6351423, -1.1040494, -0.9031536, -2.797814,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>[0.4533549, 0.007047168, -1.6182576, -0.951273...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>[1.323639, 0.20193408, -0.79267466, -1.0947683...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1894 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c234363d-e5ab-433f-b673-8e74a06b43e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c234363d-e5ab-433f-b673-8e74a06b43e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c234363d-e5ab-433f-b673-8e74a06b43e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   BERT  class\n",
              "0     [-0.12731451, -0.49048722, 0.8446229, 0.259153...      2\n",
              "1     [-0.007940845, -0.35844922, 0.64526886, 1.4159...      0\n",
              "2     [-0.14694825, -0.15108207, 0.61844623, 0.22090...      2\n",
              "3     [-0.39919105, -0.77086115, 0.91552955, 0.41431...      0\n",
              "4     [0.37260002, -0.15834673, 0.7876212, 1.0688679...      0\n",
              "...                                                 ...    ...\n",
              "1889  [-0.08940428, -0.048215955, 0.54252553, 0.1527...      2\n",
              "1890  [-0.09964228, 0.2793295, -1.509599, -0.6494946...      1\n",
              "1891  [1.6351423, -1.1040494, -0.9031536, -2.797814,...      1\n",
              "1892  [0.4533549, 0.007047168, -1.6182576, -0.951273...      1\n",
              "1893  [1.323639, 0.20193408, -0.79267466, -1.0947683...      1\n",
              "\n",
              "[1894 rows x 2 columns]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert = pd.Series(BERT)\n",
        "d = {'BERT': bert, 'class': train_data[:][2]}\n",
        "classification_df = pd.DataFrame(data = d)\n",
        "classification_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObkrfeGyvTiV"
      },
      "outputs": [],
      "source": [
        "classification_df.to_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/classification_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnGK2RaJvitz",
        "outputId": "99880fa6-84d2-4dd0-a5f6-eb283c2b1f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored 'model' (BertForSequenceClassification)\n"
          ]
        }
      ],
      "source": [
        "%store model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhfA47c3KKa3"
      },
      "outputs": [],
      "source": [
        "model.cpu()\n",
        "BERT_validation = []\n",
        "\n",
        "for i in range(len(validation_data)):\n",
        "  out = model.forward(validation_data[i:i+1][0], attention_mask=validation_data[i:i+1][1], output_hidden_states=True)\n",
        "  Sentence_Embedding = out['hidden_states'][-1][0][0].detach().numpy()\n",
        "  BERT_validation.append(Sentence_Embedding)\n",
        "# BERT.append(Sentence_Embedding)\n",
        "# print(out.keys())\n",
        "# print(out['hidden_states'][-1].shape)\n",
        "\n",
        "# Use the vector representation of [CLS] token as the sentence embedding\n",
        "# Sentence_Embedding = out['hidden_states'][-1][0][0].detach().numpy()\n",
        "# Sentence_Embedding.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ud8FqKrdg_pD",
        "outputId": "5eda1eac-7a55-4035-c148-6a711e2b9baa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7d7e12d-47a2-4022-8424-f8f27642f115\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BERT</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.28990933, -0.48097312, 0.13375153, 0.06122...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.7880645, -0.9040965, 0.42353922, 0.14112216...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1.2053293, -0.48301965, -0.6003597, -0.741756...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.037450455, -1.1154842, 1.168601, 0.6066721...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.6025331, -0.08868365, 0.49975565, -0.498329...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>[0.39436767, -0.42208368, 0.99308145, 0.597421...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>[-0.5526609, -0.7062738, 0.6757368, 0.13619643...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>[-0.43905485, -0.8510437, 1.0037291, 1.2826824...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>[0.3026767, -1.1887829, 1.0611136, -0.8916653,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>[0.100147255, -0.284045, 1.150242, 0.20905752,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>165 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7d7e12d-47a2-4022-8424-f8f27642f115')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7d7e12d-47a2-4022-8424-f8f27642f115 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7d7e12d-47a2-4022-8424-f8f27642f115');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  BERT  class\n",
              "0    [-0.28990933, -0.48097312, 0.13375153, 0.06122...      0\n",
              "1    [0.7880645, -0.9040965, 0.42353922, 0.14112216...      2\n",
              "2    [1.2053293, -0.48301965, -0.6003597, -0.741756...      1\n",
              "3    [-0.037450455, -1.1154842, 1.168601, 0.6066721...      0\n",
              "4    [0.6025331, -0.08868365, 0.49975565, -0.498329...      1\n",
              "..                                                 ...    ...\n",
              "160  [0.39436767, -0.42208368, 0.99308145, 0.597421...      2\n",
              "161  [-0.5526609, -0.7062738, 0.6757368, 0.13619643...      0\n",
              "162  [-0.43905485, -0.8510437, 1.0037291, 1.2826824...      0\n",
              "163  [0.3026767, -1.1887829, 1.0611136, -0.8916653,...      1\n",
              "164  [0.100147255, -0.284045, 1.150242, 0.20905752,...      2\n",
              "\n",
              "[165 rows x 2 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert = pd.Series(BERT_validation)\n",
        "d = {'BERT': bert, 'class': validation_data[:][2]}\n",
        "classification_test_df = pd.DataFrame(data = d)\n",
        "classification_test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_IbuuEBygsL"
      },
      "outputs": [],
      "source": [
        "classification_test_df.to_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/classification_test_df.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HI37N813llT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "# from pylab import rcParams\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bSAudRI3dvc"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix_binary_classes(y_test,y_pred):\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  ax = sns.heatmap(confusion_matrix(y_test,y_pred ), annot=True, cmap='PuBuGn')\n",
        "  plt.xlabel('Predictions', fontsize=18)\n",
        "  plt.ylabel('Actuals', fontsize=18)\n",
        "  plt.title('SVM Confusion Matrix', fontsize=18)\n",
        "  plt.show()\n",
        "  print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px-ACYPIzirD"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "def add_padding(X):\n",
        "  return np.array(list(zip(*itertools.zip_longest(*X , fillvalue=0))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3oFSJOHyow7",
        "outputId": "31f8a7b3-2193-4381-d098-a97d98e2d653"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_train= add_padding(classification_df[\"BERT\"].to_numpy())\n",
        "y_train= classification_df[\"class\"].to_numpy()\n",
        "X_test = add_padding(classification_test_df[\"BERT\"].to_numpy())\n",
        "y_test = classification_test_df[\"class\"].to_numpy()\n",
        "\n",
        "clf = svm.SVC(decision_function_shape='ovo')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred  = clf.predict(X_train)\n",
        "accuracy_score(y_train,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_n5vUWwyop7",
        "outputId": "f0668a41-2c4f-41cd-9d48-b38995234400"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5757575757575758"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred  = clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "WDw2xQlw1jxs",
        "outputId": "0d95b8eb-64f6-4506-c309-2b2198d2d405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[35 12 11]\n",
            " [22 21 12]\n",
            " [ 2 11 39]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.60      0.60        58\n",
            "           1       0.48      0.38      0.42        55\n",
            "           2       0.63      0.75      0.68        52\n",
            "\n",
            "    accuracy                           0.58       165\n",
            "   macro avg       0.57      0.58      0.57       165\n",
            "weighted avg       0.57      0.58      0.57       165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "confusion_matrix_binary_classes(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fCyMYfc3_97"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import validation_curve\n",
        "def plot_cv_indices(clf, X, y,param_name,parameter_range,  cv=10,model_name =\"SVM\"):\n",
        " \n",
        "  train_score, test_score = validation_curve(clf, X, y,\n",
        "                                       param_name = param_name,\n",
        "                                       param_range = parameter_range,\n",
        "                                        cv = cv, scoring = \"accuracy\",n_jobs=2)\n",
        " \n",
        "# Calculating mean and standard deviation of training score\n",
        "  mean_train_score = np.mean(train_score, axis = 1)\n",
        "  std_train_score = np.std(train_score, axis = 1)\n",
        " \n",
        "# Calculating mean and standard deviation of testing score\n",
        "  mean_test_score = np.mean(test_score, axis = 1)\n",
        "  std_test_score = np.std(test_score, axis = 1)\n",
        " \n",
        "# Plot mean accuracy scores for training and testing scores\n",
        "  plt.plot(parameter_range, mean_train_score,\n",
        "     label = \"Training Score\", color = 'b')\n",
        "  plt.plot(parameter_range, mean_test_score,\n",
        "   label = \"Cross Validation Score\", color = 'g')\n",
        " \n",
        "# Creating the plot\n",
        "  plt.title(f\"Validation Curve with {model_name} Classifier\")\n",
        "  plt.xlabel(f\"Value of {param_name}\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.tight_layout()\n",
        "  plt.legend(loc = 'best')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGea1bSK4w7D"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def plot_cross_val_scores(scores):\n",
        "  plt.bar(range(1,len(scores)+1,1) , scores, width=0.5)\n",
        "  \n",
        "\n",
        "  plt.title(\"The score for each train-and-validation run\")\n",
        "  plt.xlabel(\"train-and-validation run\")\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.show()\n",
        "\n",
        "def mesure_cross_vall(clf, X_train, y_train, cv=10):\n",
        "  scores = cross_val_score(clf, X_train, y_train, cv=cv)\n",
        "  print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "  print(\"K-fold cross validation score: fo each \",scores)\n",
        "  return scores\n",
        "\n",
        "def evaluate_bias_variance(clf, X_train, y_train, X_test, y_test):\n",
        "  avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        clf, X_train, y_train, X_test, y_test, \n",
        "        loss='0-1_loss',random_seed=123)\n",
        "  print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "  print('Av erage bias: %.3f' % avg_bias)\n",
        "  print('Average variance: %.3f' % avg_var)\n",
        "\n",
        "def model_evaluation(clf, X_train, y_train,cv=10):\n",
        "  scores = mesure_cross_vall(clf, X_train, y_train, cv)\n",
        "  #plot_cross_val_scores(scores)\n",
        "  # evaluate_bias_variance(clf, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "vUiwVM7l3E_K",
        "outputId": "d8161cc0-fb50-4252-f3af-e3df6b877cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.00 (+/- 0.00)\n",
            "K-fold cross validation score: fo each  [1. 1. 1. 1. 1.]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "clfbknn = KNeighborsClassifier(n_neighbors=4)\n",
        "model_evaluation(clfbknn, X_train, y_train, cv=5)\n",
        "param_range = np.arange(1, 11, 1)\n",
        "plot_cv_indices(clfbknn, X_train, y_train ,\"n_neighbors\", param_range ,  cv=10 ,model_name = \"KNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2RYlkQI5YXD",
        "outputId": "f43a63f8-6e32-46e8-e510-08b66278f860"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5757575757575758"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfbknn.fit(X_train, y_train)\n",
        "y_pred  = clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rREVuMKt6CaT",
        "outputId": "ca598c75-778a-4c54-d1e5-c13017d3303c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5818181818181818"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_pred  = gnb.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BpfFu7Tn6Yo9",
        "outputId": "424d8b86-cfa0-40cc-afbf-e02a995c321f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22754c74-ebcc-4621-82dc-47f4f8f171f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>' فينو الاهبل ابن الاهبل '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>' على المصرييييين وجمالهم ربنا يحميهم #MinaAtt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>' @Kholoudkewan  دول كتير اوى ودمهم خفيف العما...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>' انا بعد كده  خلى اللى يوعنى   بحاجه همضى على...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>' انا هنتحر '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>683</td>\n",
              "      <td>' كاستيلو المنتزه بقا خره نيك '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>684</td>\n",
              "      <td>' @badorh666 اهم شئ ...الطاعة ..... '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>685</td>\n",
              "      <td>' ايووووووووه بقى يا مينوووو وحشتنااااا #مينا_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>686</td>\n",
              "      <td>' العشرى جون #الزمالك الاول جول واحمد الله لان...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>687</td>\n",
              "      <td>' @AsmaaElwasek ازاي اسماء '</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>687 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22754c74-ebcc-4621-82dc-47f4f8f171f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22754c74-ebcc-4621-82dc-47f4f8f171f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22754c74-ebcc-4621-82dc-47f4f8f171f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Id                                              tweet\n",
              "0      1                         ' فينو الاهبل ابن الاهبل '\n",
              "1      2  ' على المصرييييين وجمالهم ربنا يحميهم #MinaAtt...\n",
              "2      3  ' @Kholoudkewan  دول كتير اوى ودمهم خفيف العما...\n",
              "3      4  ' انا بعد كده  خلى اللى يوعنى   بحاجه همضى على...\n",
              "4      5                                      ' انا هنتحر '\n",
              "..   ...                                                ...\n",
              "682  683                    ' كاستيلو المنتزه بقا خره نيك '\n",
              "683  684              ' @badorh666 اهم شئ ...الطاعة ..... '\n",
              "684  685  ' ايووووووووه بقى يا مينوووو وحشتنااااا #مينا_...\n",
              "685  686  ' العشرى جون #الزمالك الاول جول واحمد الله لان...\n",
              "686  687                       ' @AsmaaElwasek ازاي اسماء '\n",
              "\n",
              "[687 rows x 2 columns]"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d_test = pd.read_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/test.csv\")\n",
        "d_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE7DHp9-8D2L"
      },
      "outputs": [],
      "source": [
        "model.cpu()\n",
        "BERT_test = []\n",
        "\n",
        "for i in range(len(submit_data)):\n",
        "  out = model.forward(submit_data[i:i+1][0], attention_mask=submit_data[i:i+1][1], output_hidden_states=True)\n",
        "  Sentence_Embedding = out['hidden_states'][-1][0][0].detach().numpy()\n",
        "  BERT_test.append(Sentence_Embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6ZNFSEA6TU7"
      },
      "outputs": [],
      "source": [
        "y_pred_final  = gnb.predict(add_padding(np.array(BERT_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KT3gkIN--tz"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\"Id\":np.arange(1, len(y_pred_final)+1), \"class\":y_pred_final})\n",
        "# save (submission)\n",
        "submission.to_csv(\"/content/drive/MyDrive/DEBI/uottawa/Ds applications/kaggle competition/submission4.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ISXauhiUSh4",
        "outputId": "8beb782c-62ad-4728-f2d7-1eaff91101fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.9377410298791425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 1/5 [01:21<05:27, 81.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6229395604395604\n",
            "Train loss: 0.6494704225453837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [02:47<04:12, 84.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6092032967032966\n",
            "Train loss: 0.3438927285887044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [04:14<02:50, 85.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5947802197802198\n",
            "Train loss: 0.1745320632411488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [05:40<01:25, 85.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5995879120879121\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm, trange\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "t = []\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs \n",
        "epochs = 5\n",
        "\n",
        "# Transfer the model to GPU\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids.to(\"cuda\"), token_type_ids=None, attention_mask=b_input_mask.to(\"cuda\"), labels=b_labels.to(\"cuda\"))[\"loss\"]\n",
        "    train_loss_set.append(loss.item())\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    # batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids.to(\"cuda\"), token_type_ids=None, attention_mask=b_input_mask.to(\"cuda\"))\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits[\"logits\"].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of SentimentAnalysisArabicTweets.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "9c95c531f64bb638245c5025a4f7238f0b408564e6b5a3de1680f033a334bc61"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
